{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bece3f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463357ef",
   "metadata": {},
   "source": [
    "## Notebook for the implementation and evaluation of the k-Nearest Neighbor algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df24d5d",
   "metadata": {},
   "source": [
    "(basic info about file structure and running)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93cda86",
   "metadata": {},
   "source": [
    "#### Reading the data from 2025 & 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1686401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2025 = xr.open_dataset(\"files/2025_KVS_deployment_flagged.nc\")\n",
    "ds_2024 = xr.open_dataset(\"files/2024_KVS_deployment_flagged.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c433d2d",
   "metadata": {},
   "source": [
    "We calculate the difference between 1m temperature and surface temperature to train and classify based on the relationship between the surface and 1m temperature rather than just outliers in the 1m temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ffc68",
   "metadata": {},
   "source": [
    "#### A simple example of the k-NN classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point1,point2):\n",
    "    d_sum = np.sum((np.array(point1)-np.array(point2))**2)\n",
    "    return np.sqrt(d_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "255e3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_predict(X_train,X_lab,test_point,k):\n",
    "    '''\n",
    "    K Nearest Neighbor prediction funcion\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    X_train : np.array[float]\n",
    "        Training data \n",
    "\n",
    "    X_lab : np.array[int]\n",
    "        Labels for training data, in this case likely array\n",
    "        of values either 0, for normal or 1 for outlier\n",
    "    \n",
    "    test_point : float\n",
    "        The data point which we are classifying\n",
    "\n",
    "    k : int\n",
    "        Hyperparameter for k-NN algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    label : int\n",
    "        The predicted label for the test point\n",
    "\n",
    "    '''\n",
    "    dist = []\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        d = euclidean_distance(test_point,X_train[i])\n",
    "        dist.append((d,X_lab[i]))\n",
    "    dist.sort(key=lambda x: x[0])\n",
    "    k_nearest_labels = [label for _, label in dist[:k]]\n",
    "\n",
    "    return Counter(k_nearest_labels).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b330c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [[1,2],[2,3],[3,4],[6,7],[7,8]]\n",
    "X_lab = [\"A\",\"A\",\"A\",\"B\",\"B\"]\n",
    "test_point = [4,5]\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13f1b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = kNN_predict(X_train,X_lab,test_point,k)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcc1bf3",
   "metadata": {},
   "source": [
    "#### Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2025_1m_temp = ds_2025[\"temp_1m_calibrated\"]\n",
    "ds_2025_1m_labels = ds_2025[\"temp_1m_quality_flag\"]\n",
    "ds_2025_ir_temp = ds_2025[\"temp_snowsurface\"]\n",
    "ds_2025_temp_diff = ds_2025_1m_temp - ds_2025_ir_temp\n",
    "\n",
    "ds_2024_1m_temp = ds_2024[\"temp_1m_calibrated\"]\n",
    "ds_2024_1m_lab = ds_2024[\"temp_1m_quality_flag\"]\n",
    "ds_2024_ir_temp = ds_2024[\"temp_snowsurface_calibrated\"]\n",
    "ds_2024_temp_diff = ds_2024_1m_temp - ds_2024_ir_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52649c4",
   "metadata": {},
   "source": [
    "#### Choosing a k value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee22a8",
   "metadata": {},
   "source": [
    "On temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(ds_2025_1m_temp.isel(trajectory=2),test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eddf78d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2516,) (629,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train),np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d63fa87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe1a7cb5",
   "metadata": {},
   "source": [
    "Load in temperature dataset, test kNN_predict using labels and data from 2025 and test points from the 2024 dataset (also probably do a train test split for 2025 and then do the 2024)\n",
    "\n",
    "when that is done we try and visualize that, and add all of those plots to the overleaf document\n",
    "\n",
    "then using 2025 as training data and 2024 as test data, we run the actual use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fff80e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2_electric_boogalo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
